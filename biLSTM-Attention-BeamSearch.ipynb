{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown \n!gdown --id 1p79C1yIK7XEjHVpLZoJljFYDH2VSaJbr\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T13:52:39.410656Z","iopub.execute_input":"2023-05-15T13:52:39.411022Z","iopub.status.idle":"2023-05-15T13:53:08.624301Z","shell.execute_reply.started":"2023-05-15T13:52:39.410992Z","shell.execute_reply":"2023-05-15T13:53:08.623170Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.11.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.28.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m/opt/conda/lib/python3.10/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1p79C1yIK7XEjHVpLZoJljFYDH2VSaJbr\nFrom (redirected): https://drive.google.com/uc?id=1p79C1yIK7XEjHVpLZoJljFYDH2VSaJbr&confirm=t&uuid=d71377a8-6458-4216-859c-867e5620155e\nTo: /kaggle/working/Dataset.zip\n100%|████████████████████████████████████████| 829M/829M [00:11<00:00, 72.6MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-05-15T13:53:08.627061Z","iopub.execute_input":"2023-05-15T13:53:08.627461Z","iopub.status.idle":"2023-05-15T13:53:08.635016Z","shell.execute_reply.started":"2023-05-15T13:53:08.627425Z","shell.execute_reply":"2023-05-15T13:53:08.633941Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"! unzip Dataset.zip\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T13:53:08.636466Z","iopub.execute_input":"2023-05-15T13:53:08.637110Z","iopub.status.idle":"2023-05-15T13:53:21.066082Z","shell.execute_reply.started":"2023-05-15T13:53:08.637079Z","shell.execute_reply":"2023-05-15T13:53:21.064864Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  Dataset.zip\n   creating: Dataset/\n  inflating: Dataset/baomoi.model.bin  \n  inflating: Dataset/wikilingual.csv  \n  inflating: Dataset/vietnews_train.csv  \n  inflating: Dataset/vietnews_val.csv  \n  inflating: Dataset/vietnews_test.csv  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Import libraries**","metadata":{}},{"cell_type":"code","source":"import os\nimport pickle\n\nimport pandas as pd\nimport numpy as np\nimport time\nimport math\nimport random\nimport operator\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n#from pyvi import ViTokenizer, ViPosTagger\nfrom gensim.models import KeyedVectors\nfrom gensim.models.keyedvectors import KeyedVectors\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.utils.data as data\nfrom torch.autograd import Variable\n\nfrom queue import PriorityQueue\n","metadata":{"id":"EMuRPpTT4-gF","execution":{"iopub.status.busy":"2023-05-15T13:53:21.069710Z","iopub.execute_input":"2023-05-15T13:53:21.070147Z","iopub.status.idle":"2023-05-15T13:53:32.963169Z","shell.execute_reply.started":"2023-05-15T13:53:21.070107Z","shell.execute_reply":"2023-05-15T13:53:32.962219Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fs-aQyyRwuOg","outputId":"d38e4cf6-6aa0-49c3-bc4a-4951995f47c0","execution":{"iopub.status.busy":"2023-05-15T13:53:32.964624Z","iopub.execute_input":"2023-05-15T13:53:32.965349Z","iopub.status.idle":"2023-05-15T13:53:33.040637Z","shell.execute_reply.started":"2023-05-15T13:53:32.965313Z","shell.execute_reply":"2023-05-15T13:53:33.039690Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Process data**","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"Dataset/vietnews_train.csv\",index_col = 0)\nval = pd.read_csv(\"Dataset/vietnews_val.csv\", index_col = 0)\ntest = pd.read_csv(\"Dataset/vietnews_test.csv\", index_col = 0)","metadata":{"id":"J0OvTK93C4Br","execution":{"iopub.status.busy":"2023-05-15T13:53:33.042332Z","iopub.execute_input":"2023-05-15T13:53:33.043413Z","iopub.status.idle":"2023-05-15T13:53:42.406767Z","shell.execute_reply.started":"2023-05-15T13:53:33.043377Z","shell.execute_reply":"2023-05-15T13:53:42.405762Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train.drop(['file'], axis = 1, inplace = True)\nval.drop(['file'], axis = 1, inplace = True)\ntest.drop(['file'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T13:53:42.408049Z","iopub.execute_input":"2023-05-15T13:53:42.408441Z","iopub.status.idle":"2023-05-15T13:53:42.437206Z","shell.execute_reply.started":"2023-05-15T13:53:42.408401Z","shell.execute_reply":"2023-05-15T13:53:42.436125Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def process(str):\n    return '<sos> ' + str.lower() + ' <eos>'","metadata":{"id":"uTnNT1fqwuOh","execution":{"iopub.status.busy":"2023-05-15T13:53:42.438517Z","iopub.execute_input":"2023-05-15T13:53:42.439442Z","iopub.status.idle":"2023-05-15T13:53:42.443732Z","shell.execute_reply.started":"2023-05-15T13:53:42.439405Z","shell.execute_reply":"2023-05-15T13:53:42.442847Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train.original = train.original.apply(process)\nval.original = val.original.apply(process)\ntest.original = test.original.apply(process)\n","metadata":{"id":"fT0gfu7PDU6Q","execution":{"iopub.status.busy":"2023-05-15T13:53:42.444965Z","iopub.execute_input":"2023-05-15T13:53:42.445827Z","iopub.status.idle":"2023-05-15T13:53:45.950555Z","shell.execute_reply.started":"2023-05-15T13:53:42.445771Z","shell.execute_reply":"2023-05-15T13:53:45.949205Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train.summary = train.summary.apply(process)\nval.summary = val.summary.apply(process)\ntest.summary = test.summary.apply(process)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T13:53:45.967620Z","iopub.execute_input":"2023-05-15T13:53:45.967937Z","iopub.status.idle":"2023-05-15T13:53:46.357141Z","shell.execute_reply.started":"2023-05-15T13:53:45.967910Z","shell.execute_reply":"2023-05-15T13:53:46.356075Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"text_count = [len(sentence.split()) for sentence in train.original]\nheadlines_count = [len(sentence.split()) for sentence in train.summary]\n\npd.DataFrame({'Document': text_count, 'Summary': headlines_count}).hist(bins=100, figsize=(16, 4), range=[0, 1200])\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"CmAN58yr_Kov","outputId":"092b6230-2fdb-4e88-e499-b714579fec90","execution":{"iopub.status.busy":"2023-05-15T13:53:46.359876Z","iopub.execute_input":"2023-05-15T13:53:46.360178Z","iopub.status.idle":"2023-05-15T13:53:51.283877Z","shell.execute_reply.started":"2023-05-15T13:53:46.360152Z","shell.execute_reply":"2023-05-15T13:53:51.282951Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1600x400 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"def get_word_percent(column, limit):\n    count = 0\n    for sentence in column:\n        if len(sentence.split()) <= limit:\n            count += 1\n\n    return round(count / len(column), 2)\n\nprint(get_word_percent(train.original, 800))\n\nprint(get_word_percent(train.summary, 50))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dtq8qpQgA1jx","outputId":"a58ab345-f456-45bc-e939-a0575b19e322","execution":{"iopub.status.busy":"2023-05-15T13:53:51.285346Z","iopub.execute_input":"2023-05-15T13:53:51.285905Z","iopub.status.idle":"2023-05-15T13:53:55.255669Z","shell.execute_reply.started":"2023-05-15T13:53:51.285870Z","shell.execute_reply":"2023-05-15T13:53:55.254593Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"0.93\n0.98\n","output_type":"stream"}]},{"cell_type":"code","source":"max_text_len = 800\nmax_summary_len = 50\n\ndef trim_text_and_summary(df, max_text_len, max_summary_len):\n    cleaned_text = np.array(df['original'])\n    cleaned_summary = np.array(df['summary'])\n\n    short_text = []\n    short_summary = []\n\n    for i in range(len(cleaned_text)):\n        if len(cleaned_text[i].split()) <= max_text_len and len(\n            cleaned_summary[i].split()\n        ) <= max_summary_len:\n            short_text.append(cleaned_text[i])\n            short_summary.append(cleaned_summary[i])\n\n    df = pd.DataFrame({'text': short_text, 'summary': short_summary})\n    return df\n\n\ntrain = trim_text_and_summary(train, max_text_len, max_summary_len)\nval = trim_text_and_summary(val, max_text_len, max_summary_len)\ntest = trim_text_and_summary(test, max_text_len, max_summary_len)\n\nprint(f'Dataset size: {len(train)}')\ntrain.sample(5)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"9JVjT2aBBO3s","outputId":"73e94309-3208-4c43-f318-739f36a1b715","execution":{"iopub.status.busy":"2023-05-15T13:53:55.257102Z","iopub.execute_input":"2023-05-15T13:53:55.257443Z","iopub.status.idle":"2023-05-15T13:54:00.996425Z","shell.execute_reply.started":"2023-05-15T13:53:55.257411Z","shell.execute_reply":"2023-05-15T13:54:00.993522Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Dataset size: 96388\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                    text  \\\n46395  <sos> tổng_thống mỹ donald_trump ( phải ) và n...   \n36576  <sos> tình_báo mỹ đang theo_dõi một loạt các c...   \n8184   <sos> kate_mcclure và johnny_bobbitt_jr khi gặ...   \n42286  <sos> tổng_thống mỹ barack_obama phát_biểu tại...   \n14619  <sos> đồ cúng của một_số người indonesia tin v...   \n\n                                                 summary  \n46395  <sos> vùng_đệm an_ninh nhằm đảm_bảo an_toàn ch...  \n36576  <sos> cả mỹ và israel đang lo_ngại một_số chuy...  \n8184   <sos> johnny bobbitt_jr . được cộng_đồng quyên...  \n42286  <sos> tổng_thống barack_obama chế_giễu donald_...  \n14619  <sos> gia_đình indonesia cho_rằng việc giữ thi...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>46395</th>\n      <td>&lt;sos&gt; tổng_thống mỹ donald_trump ( phải ) và n...</td>\n      <td>&lt;sos&gt; vùng_đệm an_ninh nhằm đảm_bảo an_toàn ch...</td>\n    </tr>\n    <tr>\n      <th>36576</th>\n      <td>&lt;sos&gt; tình_báo mỹ đang theo_dõi một loạt các c...</td>\n      <td>&lt;sos&gt; cả mỹ và israel đang lo_ngại một_số chuy...</td>\n    </tr>\n    <tr>\n      <th>8184</th>\n      <td>&lt;sos&gt; kate_mcclure và johnny_bobbitt_jr khi gặ...</td>\n      <td>&lt;sos&gt; johnny bobbitt_jr . được cộng_đồng quyên...</td>\n    </tr>\n    <tr>\n      <th>42286</th>\n      <td>&lt;sos&gt; tổng_thống mỹ barack_obama phát_biểu tại...</td>\n      <td>&lt;sos&gt; tổng_thống barack_obama chế_giễu donald_...</td>\n    </tr>\n    <tr>\n      <th>14619</th>\n      <td>&lt;sos&gt; đồ cúng của một_số người indonesia tin v...</td>\n      <td>&lt;sos&gt; gia_đình indonesia cho_rằng việc giữ thi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_train,y_train = train.text, train.summary\nx_val,y_val = val.text, val.summary\nx_test,y_test = test.text, test.summary\n","metadata":{"id":"Wn6pYLZqwuOk","execution":{"iopub.status.busy":"2023-05-15T13:54:00.998402Z","iopub.execute_input":"2023-05-15T13:54:00.999300Z","iopub.status.idle":"2023-05-15T13:54:01.015489Z","shell.execute_reply.started":"2023-05-15T13:54:00.999232Z","shell.execute_reply":"2023-05-15T13:54:01.014643Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"x_tokenizer = Tokenizer()\nx_tokenizer.fit_on_texts(list(x_train))\nx_train_sequence = x_tokenizer.texts_to_sequences(x_train)\nx_val_sequence = x_tokenizer.texts_to_sequences(x_val)\nx_test_sequence = x_tokenizer.texts_to_sequences(x_test)\n\n# padding upto max_text_len\nx_train_padded = pad_sequences(x_train_sequence, maxlen=max_text_len, padding='post')\nx_val_padded = pad_sequences(x_val_sequence, maxlen=max_text_len, padding='post')\nx_test_padded = pad_sequences(x_test_sequence, maxlen=max_text_len, padding='post')\n\ny_tokenizer = Tokenizer()\ny_tokenizer.fit_on_texts(list(y_train))\n\ny_train_sequence = y_tokenizer.texts_to_sequences(y_train)\ny_val_sequence = y_tokenizer.texts_to_sequences(y_val)\ny_test_sequence = y_tokenizer.texts_to_sequences(y_test)\n\n# padding upto max_summary_len\ny_train_padded = pad_sequences(y_train_sequence, maxlen=max_summary_len, padding='post')\ny_val_padded = pad_sequences(y_val_sequence, maxlen=max_summary_len, padding='post')\ny_test_padded = pad_sequences(y_test_sequence, maxlen=max_summary_len, padding='post')\n\n\n# if you're not using num_words parameter in Tokenizer then use this\nx_vocab_size = len(x_tokenizer.word_index) + 1\ny_vocab_size = len(y_tokenizer.word_index) + 1\n# else use this\n# x_vocab_size = tokenizer.num_words + 1\n\nprint(y_vocab_size)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fMvEQ67HwuOk","outputId":"4f498039-7da4-47ea-f66c-b91a27bdb1df","execution":{"iopub.status.busy":"2023-05-15T13:54:01.018452Z","iopub.execute_input":"2023-05-15T13:54:01.022055Z","iopub.status.idle":"2023-05-15T13:56:18.075399Z","shell.execute_reply.started":"2023-05-15T13:54:01.022019Z","shell.execute_reply":"2023-05-15T13:56:18.074284Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"21946\n","output_type":"stream"}]},{"cell_type":"code","source":"SOS_token = y_tokenizer.word_index['sos']\nEOS_token = y_tokenizer.word_index['eos']\nPAD_index = 0\nx_EOS_token = x_tokenizer.word_index['eos']\nprint(\"SOS token: \",SOS_token)\nprint(\"EOS token: \",EOS_token)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjZ-WSuAwuOm","outputId":"8bad6442-11de-4be7-df43-de7af0b17eec","execution":{"iopub.status.busy":"2023-05-15T13:56:18.076945Z","iopub.execute_input":"2023-05-15T13:56:18.077278Z","iopub.status.idle":"2023-05-15T13:56:18.084861Z","shell.execute_reply.started":"2023-05-15T13:56:18.077247Z","shell.execute_reply":"2023-05-15T13:56:18.082771Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"SOS token:  1\nEOS token:  2\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_size = 400\nword_vectors = KeyedVectors.load_word2vec_format('Dataset/baomoi.model.bin', binary=True)\nnum_words_x = len(x_tokenizer.word_index) + 1\nx_embedding_matrix = np.zeros((num_words_x, embedding_size))\nfor word, i in x_tokenizer.word_index.items():\n    if word in word_vectors:\n        x_embedding_matrix[i] = word_vectors[word]\n    else:\n        x_embedding_matrix[i] = np.random.normal(size=(embedding_size,))\nnum_words_y = len(y_tokenizer.word_index) + 1\ny_embedding_matrix = np.zeros((num_words_y, embedding_size))\nfor word, i in y_tokenizer.word_index.items():\n    if word in word_vectors:\n        y_embedding_matrix[i] = word_vectors[word]\n    else:\n        y_embedding_matrix[i] = np.random.normal(size=(embedding_size,))\n","metadata":{"id":"o14hZkRdwuOn","execution":{"iopub.status.busy":"2023-05-15T13:56:18.086389Z","iopub.execute_input":"2023-05-15T13:56:18.087271Z","iopub.status.idle":"2023-05-15T13:56:26.080862Z","shell.execute_reply.started":"2023-05-15T13:56:18.087234Z","shell.execute_reply":"2023-05-15T13:56:26.079794Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import torch.utils.data as data\n\ntrain_dataset = data.TensorDataset(torch.tensor(x_train_padded,dtype = torch.long).to(device), torch.tensor(y_train_padded,dtype = torch.long).to(device))\ntrain_dataloader = data.DataLoader(train_dataset, batch_size = 64, shuffle= True)\nval_dataset = data.TensorDataset(torch.tensor(x_val_padded,dtype = torch.long).to(device), torch.tensor(y_val_padded,dtype = torch.long).to(device))\nval_dataloader = data.DataLoader(val_dataset, batch_size = 64, shuffle= True)\ntest_dataset = data.TensorDataset(torch.tensor(x_test_padded,dtype = torch.long).to(device), torch.tensor(y_test_padded,dtype = torch.long).to(device))\ntest_dataloader = data.DataLoader(test_dataset, batch_size = 64, shuffle= True)","metadata":{"id":"wu9nfpvNwuOo","execution":{"iopub.status.busy":"2023-05-15T13:56:26.082242Z","iopub.execute_input":"2023-05-15T13:56:26.082610Z","iopub.status.idle":"2023-05-15T13:56:32.645282Z","shell.execute_reply.started":"2023-05-15T13:56:26.082576Z","shell.execute_reply":"2023-05-15T13:56:32.644251Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# **Modelling**","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, embedding_weight):\n        super().__init__()\n        \n        # initializations\n        self.hid_dim = hid_dim\n        self.n_layers = n_layers\n        self.embedding = nn.Embedding(input_dim, emb_dim)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_weight, dtype= torch.float32),requires_grad= False)\n        # we will use 2 layers for both encoder and decoder\n        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, src):\n        \n        #src = [src len, batch size]\n        \n        embedded = self.dropout(self.embedding(src))\n        \n        #embedded = [src len, batch size, emb dim]\n        \n        outputs, hidden = self.rnn(embedded)\n        \n        #outputs = [src len, batch size, hid dim * n directions]\n        #hidden = [n layers * n directions, batch size, hid dim]\n        #cell = [n layers * n directions, batch size, hid dim]\n        \n        #outputs are always from the top hidden layer\n        \n        return outputs,hidden\n \n\nclass Attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention, self).__init__()\n        self.hidden_size = hidden_size\n        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n        self.v = nn.Parameter(torch.randn_like(torch.empty(hidden_size)))\n\n    def forward(self, hidden, encoder_outputs):\n        sequence_length = encoder_outputs.size(0)\n        h = hidden.repeat_interleave(sequence_length, dim=0)\n        h = h.view(sequence_length, -1, self.hidden_size).transpose(0, 1)\n        encoder_outputs = encoder_outputs.transpose(0, 1)\n        energy = F.relu(self.attn(torch.cat((h, encoder_outputs), dim=2)))\n        energy = energy.transpose(1, 2)\n        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)\n        energy = torch.matmul(v, energy)\n        return F.softmax(energy.squeeze(1), dim=1).unsqueeze(1)\n\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, embedding_weight):\n        super().__init__()\n        \n        # initialize\n        self.output_dim = output_dim\n        self.hid_dim = hid_dim\n        self.n_layers = n_layers\n        self.embedding = nn.Embedding(output_dim, emb_dim)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_weight, dtype=torch.float32), requires_grad=False)\n\n        # for decoder we will use n_directions 1\n        self.rnn = nn.LSTM(emb_dim + hid_dim, hid_dim, n_layers, dropout=dropout)\n        # fully connected layer to predict words\n        self.fc_out = nn.Linear(hid_dim*2, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.attention = Attention(hid_dim)\n\n\n    def forward(self, trg, hidden, encoder_outputs):\n        # trg = [batch size]\n        # hidden = [n layers * n directions, batch size, hid dim]\n        # cell = [n layers * n directions, batch size, hid dim]\n        # encoder_outputs = [src len, batch size, hid dim]\n\n        # n directions in the decoder will always be 1, therefore:\n        # hidden = [n layers, batch size, hid dim]\n        # context = [n layers, batch size, hid dim]\n        (hidden,cell) = hidden\n\n        # trg = [1, batch size]\n\n        embedded = self.dropout(self.embedding(trg).unsqueeze(0))\n\n        # embedded = [1, batch size, emb dim]\n\n        # Calculate attention scores\n        attn_weights = self.attention(hidden[-1], encoder_outputs)  # [32, 512][27, 32, 512]=>[32, 1, 27]\n        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,N) # [32, 1, 27]bmm[32, 27, 512]=>[32,1,512]\n        context = context.transpose(0, 1)  # (1,B,N) # [32, 1, 512]=>[1, 32, 512]\n        # Combine embedded input word and attended context, run through RNN\n        rnn_input = torch.cat([embedded, context], 2)  # [1, 32, 256] cat [1, 32, 512]=> [1, 32, 768]\n\n        output, hidden = self.rnn(rnn_input, (hidden, cell))\n\n        # output = [seq len, batch size, hid dim * n directions]\n        # hidden = [n layers * n directions, batch size, hid dim]\n        # cell = [n layers * n directions, batch size, hid dim]\n\n        # seq len and n directions will always be 1 in the decoder, therefore:\n        # output = [1, batch size, hid dim]\n        # hidden = [n layers, batch size, hid dim]\n        # cell = [n layers, batch size, hid dim]\n        output = output.squeeze(0)  # (1,B,N) -> (B,N)\n        context = context.squeeze(0)\n        output = self.fc_out(torch.cat([output, context], 1))  # [32, 512] cat [32, 512] => [32, 512*2]\n        output = F.log_softmax(output, dim=1)\n\n\n        # prediction = [batch size, output dim]\n\n        return output, hidden\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device, beam_size=5):\n        super().__init__()\n        \n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        self.beam_size = beam_size\n        \n        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n        #assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have equal number of layers!\"\n        \n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        #src = [src len, batch size] where src_len is number of tokens in source sentence\n        #trg = [trg len, batch size] same for trg_len\n        #teacher_forcing_ratio is probability to use teacher forcing\n        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n        \n        batch_size = trg.shape[1]\n        trg_len = trg.shape[0]\n        trg_vocab_size = self.decoder.output_dim # we don't have trg.shape[-1] here\n        \n        #tensor to store decoder outputs\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n        \n        #last hidden state of the encoder is used as the initial hidden state of the decoder\n        encoder_outputs, (hidden, cell) = self.encoder(src)\n        hidden, cell = hidden[:self.decoder.n_layers], cell[:self.decoder.n_layers]\n        #first input to the decoder is the <sos> tokens\n        dec_input = trg[0,:]\n        \n\n        for t in range(1, trg_len):\n            \n            #insert input token embedding, previous hidden and previous cell states\n            #receive output tensor (predictions) and new hidden and cell states\n            \n            output, (hidden, cell) = self.decoder(dec_input, (hidden, cell), encoder_outputs)\n            \n            #place predictions in a tensor holding predictions for each token\n            outputs[t] = output\n            \n            #decide if we are going to use teacher forcing or not\n            teacher_force = random.random() < teacher_forcing_ratio\n            \n            #get the highest predicted token from our predictions\n            top1 = output.argmax(1) \n            \n            #if teacher forcing, use actual next token as next input\n            #if not, use predicted token\n            dec_input = trg[t] if teacher_force else top1\n        \n        return outputs\n    def decode(self, src, trg, method='beam-search'):\n        encoder_output, (hidden, cell) = self.encoder(src)  # [27, 32]=> =>[27, 32, 512],[4, 32, 512]\n        hidden, cell = hidden[:self.decoder.n_layers], cell[:self.decoder.n_layers]  # [4, 32, 512][1, 32, 512]\n        if method == 'beam-search':\n            return self.beam_decode(trg, (hidden,cell), encoder_output)\n        else:\n            return self.greedy_decode(trg, (hidden, cell), encoder_output)\n\n    def greedy_decode(self, trg, decoder_hidden, encoder_outputs, ):\n        '''\n        :param target_tensor: target indexes tensor of shape [B, T] where B is the batch size and T is the maximum length of the output sentence\n        :param decoder_hidden: input tensor of shape [1, B, H] for start of the decoding\n        :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n        :return: decoded_batch\n        '''\n        seq_len, batch_size = trg.size()\n        decoded_batch = torch.zeros((batch_size, seq_len))\n        # decoder_input = torch.LongTensor([[EN.vocab.stoi['<sos>']] for _ in range(batch_size)]).cuda()\n        decoder_input = Variable(trg.data[0, :]).cuda()  # sos\n        print(decoder_input.shape)\n        for t in range(seq_len):\n            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n\n            topv, topi = decoder_output.data.topk(1)  # [32, 10004] get candidates\n            topi = topi.view(-1)\n            decoded_batch[:, t] = topi\n\n            decoder_input = topi.detach().view(-1)\n\n        return decoded_batch\n\n\n    def beam_decode(self, target_tensor, decoder_hiddens, encoder_outputs=None):\n        '''\n        :param target_tensor: target indexes tensor of shape [B, T] where B is the batch size and T is the maximum length of the output sentence\n        :param decoder_hiddens: input tensor of shape [1, B, H] for start of the decoding\n        :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n        :return: decoded_batch\n        '''\n        target_tensor = target_tensor.permute(1, 0)\n        beam_width = 10\n        topk = 1  # how many sentence do you want to generate\n        decoded_batch = []\n\n        # decoding goes sentence by sentence\n        for idx in range(target_tensor.size(0)):  # batch_size\n            if isinstance(decoder_hiddens, tuple):  # LSTM case\n                decoder_hidden = (\n                    decoder_hiddens[0][:, idx, :].unsqueeze(0), decoder_hiddens[1][:, idx, :].unsqueeze(0))\n            else:\n                decoder_hidden = decoder_hiddens[:, idx, :].unsqueeze(0)  # [1, B, H]=>[1,H]=>[1,1,H]\n            encoder_output = encoder_outputs[:, idx, :].unsqueeze(1)  # [T,B,H]=>[T,H]=>[T,1,H]\n\n            # Start with the start of the sentence token\n            decoder_input = torch.LongTensor([SOS_token]).cuda()\n\n            # Number of sentence to generate\n            endnodes = []\n            number_required = min((topk + 1), topk - len(endnodes))\n\n            # starting node -  hidden vector, previous node, word id, logp, length\n            node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n            nodes = PriorityQueue()\n\n            # start the queue\n            nodes.put((-node.eval(), node))\n            qsize = 1\n\n            # start beam search\n            while True:\n                # give up when decoding takes too long\n                if qsize > 2000: break\n\n                # fetch the best node\n                score, n = nodes.get()\n                # print('--best node seqs len {} '.format(n.leng))\n                decoder_input = n.wordid\n                decoder_hidden = n.h\n\n                if n.wordid.item() == EOS_token and n.prevNode != None:\n                    endnodes.append((score, n))\n                    # if we reached maximum # of sentences required\n                    if len(endnodes) >= number_required:\n                        break\n                    else:\n                        continue\n\n                # decode for one step using decoder\n                decoder_output, decoder_hidden  = self.decoder(decoder_input, decoder_hidden, encoder_output)\n\n                # PUT HERE REAL BEAM SEARCH OF TOP\n                log_prob, indexes = torch.topk(decoder_output, beam_width)\n                nextnodes = []\n\n                for new_k in range(beam_width):\n                    decoded_t = indexes[0][new_k].view(-1)\n                    log_p = log_prob[0][new_k].item()\n\n                    node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n                    score = -node.eval()\n                    nextnodes.append((score, node))\n\n                # put them into queue\n                for i in range(len(nextnodes)):\n                    score, nn = nextnodes[i]\n                    nodes.put((score, nn))\n                    # increase qsize\n                qsize += len(nextnodes) - 1\n\n            # choose nbest paths, back trace them\n            if len(endnodes) == 0:\n                endnodes = [nodes.get() for _ in range(topk)]\n\n            utterances = []\n            for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n                utterance = []\n                utterance.append(n.wordid)\n                # back trace\n                while n.prevNode != None:\n                    n = n.prevNode\n                    utterance.append(n.wordid)\n\n                utterance = utterance[::-1]\n                utterances.append(utterance)\n\n            decoded_batch.append(utterances)\n\n        return decoded_batch\n\n\nclass BeamSearchNode(object):\n    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n        '''\n        :param hiddenstate:\n        :param previousNode:\n        :param wordId:\n        :param logProb:\n        :param length:\n        '''\n        self.h = hiddenstate\n        self.prevNode = previousNode\n        self.wordid = wordId\n        self.logp = logProb\n        self.leng = length\n\n    def eval(self, alpha=1.0):\n        reward = 0\n        # Add here a function for shaping a reward\n\n        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward  # 注意这里是有惩罚参数的，参考恩达的 beam-search\n\n    def __lt__(self, other):\n        return self.leng < other.leng  # 这里展示分数相同的时候怎么处理冲突，具体使用什么指标，根据具体情况讨论\n\n    def __gt__(self, other):\n        return self.leng > other.leng","metadata":{"id":"oBKFtOFGQ5Fj","execution":{"iopub.status.busy":"2023-05-15T13:56:32.646938Z","iopub.execute_input":"2023-05-15T13:56:32.647288Z","iopub.status.idle":"2023-05-15T13:56:32.708243Z","shell.execute_reply.started":"2023-05-15T13:56:32.647256Z","shell.execute_reply":"2023-05-15T13:56:32.707395Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\nimport math\nclass Seq2Seq_trainer(object):\n    def __init__(self, model, train_iterator, valid_iterator, pad_index, device, clip, learning_rate):\n        # initialize config variables\n        self.model = model.to(device)\n        self.train_iterator = train_iterator\n        self.valid_iterator = valid_iterator\n        self.clip = clip\n        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n        # TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n        self.criterion = nn.CrossEntropyLoss(ignore_index = pad_index)\n        self.model.apply(self.init_weights)\n        print(f'The model has {self.count_parameters(self.model):,} trainable parameters')\n\n        \n    \n    def init_weights(self,m):\n        for name, param in m.named_parameters():\n            nn.init.uniform_(param.data, -0.08, 0.08)\n        \n    \n    def count_parameters(self, model):\n        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n    \n    def train(self):\n\n        self.model.train()\n\n        epoch_loss = 0\n        num_batches = max((i, j) for i, j in enumerate(self.train_iterator))[0]\n\n        for i, batch in enumerate(self.train_iterator):\n\n            src = batch[0].transpose(0, 1)\n            trg = batch[1].transpose(0, 1)\n\n\n            self.optimizer.zero_grad()\n\n            output = self.model(src, trg)\n\n            #trg = [trg len, batch size]\n            #output = [trg len, batch size, output dim]\n\n            output_dim = output.shape[-1]\n\n            output = output[1:].view(-1, output_dim)\n            trg = trg[1:].reshape(-1)\n\n            #trg = [(trg len - 1) * batch size]\n            #output = [(trg len - 1) * batch size, output dim]\n\n            loss = self.criterion(output, trg)\n\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n\n            self.optimizer.step()\n\n            epoch_loss += loss.item()\n            \n            if i % 100 == 0 and i != 0:\n                epoch_loss = epoch_loss / 100\n                print(\"[%d/%d][loss:%5.2f][pp:%5.2f]\" %\n                      (i, num_batches, epoch_loss, math.exp(epoch_loss)))\n        return epoch_loss / len(self.train_iterator)\n    \n    \n    def evaluate(self, iterator):\n\n        self.model.eval()\n\n        epoch_loss = 0\n\n        with torch.no_grad():\n\n            for i, batch in enumerate(iterator):\n\n                src = batch[0].transpose(0, 1)\n                trg = batch[1].transpose(0, 1)\n\n                output = self.model(src, trg, 0) #turn off teacher forcing\n\n                #trg = [trg len, batch size]\n                #output = [trg len, batch size, output dim]\n\n                output_dim = output.shape[-1]\n\n                output = output[1:].view(-1, output_dim)\n                trg = trg[1:].reshape(-1)\n\n                #trg = [(trg len - 1) * batch size]\n                #output = [(trg len - 1) * batch size, output dim]\n\n                loss = self.criterion(output, trg)\n\n                epoch_loss += loss.item()\n\n        return epoch_loss / len(iterator)\n    \n    \n    def epoch_time(self, start_time, end_time):\n        elapsed_time = end_time - start_time\n        elapsed_mins = int(elapsed_time / 60)\n        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n        return elapsed_mins, elapsed_secs\n    \n    \n    def fit(self, nepochs):\n        best_valid_loss = float('inf')\n\n        for epoch in tqdm(range(nepochs)):\n\n            start_time = time.time()\n\n            train_loss = self.train()\n            valid_loss = self.evaluate(self.valid_iterator)\n\n            end_time = time.time()\n\n            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n\n            if valid_loss < best_valid_loss:\n                best_valid_loss = valid_loss\n                # torch.save(model.state_dict(), 'tut1-model.pt')\n                print(f'Epoch with best validation loss: {epoch+1:02}')\n\n            print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n            print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n\n            \n    def predict(self, iterator):\n        self.model.eval()\n        decoded_batch_list = []\n        with torch.no_grad():\n\n            for i, batch in enumerate(tqdm(iterator)):\n\n                src = batch[0].transpose(0, 1)\n                trg = batch[1].transpose(0, 1)\n\n                decoded_batch = self.model.decode(src, trg, method='beam-search')\n                decoded_batch.to('cpu').numpy()\n                decoded_batch_list.append(decoded_batch)\n                \n        return decoded_batch_list\n","metadata":{"id":"f-8qggk_RfOz","execution":{"iopub.status.busy":"2023-05-15T13:56:32.709687Z","iopub.execute_input":"2023-05-15T13:56:32.710048Z","iopub.status.idle":"2023-05-15T13:56:32.733556Z","shell.execute_reply.started":"2023-05-15T13:56:32.710018Z","shell.execute_reply":"2023-05-15T13:56:32.732605Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def get_sentence(arr, y_tokenizer):\n  output = ''\n  for element in arr:\n    if element != 0:\n      output = output + y_tokenizer.index_word[element] + ' '\n  return output","metadata":{"execution":{"iopub.status.busy":"2023-05-15T13:56:32.734751Z","iopub.execute_input":"2023-05-15T13:56:32.735109Z","iopub.status.idle":"2023-05-15T13:56:32.747890Z","shell.execute_reply.started":"2023-05-15T13:56:32.735078Z","shell.execute_reply":"2023-05-15T13:56:32.746991Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# **Attention Seq2seq: BiLSTM with attention and Beam search inference**","metadata":{}},{"cell_type":"code","source":"INPUT_DIM = x_vocab_size\nOUTPUT_DIM = y_vocab_size\nENC_EMB_DIM = 400\nDEC_EMB_DIM = 400\nHID_DIM = 200\nN_LAYERS = 2\nENC_DROPOUT = 0.1\nDEC_DROPOUT = 0.1\n\n# initialize seq2seq model\nenc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT, x_embedding_matrix)\ndec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, 1, DEC_DROPOUT, y_embedding_matrix)\nattn_model = Seq2Seq(enc, dec, device)\n\npad_index = 0\n# initialize trainer\nattn_trainer = Seq2Seq_trainer(attn_model, train_dataloader, val_dataloader, pad_index, device, 1, 1e-3)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFu9sye7El3H","outputId":"83ec4734-34be-4689-d3e7-f0fb5fe3fc0b","execution":{"iopub.status.busy":"2023-05-15T13:56:32.749292Z","iopub.execute_input":"2023-05-15T13:56:32.749775Z","iopub.status.idle":"2023-05-15T13:56:35.229365Z","shell.execute_reply.started":"2023-05-15T13:56:32.749732Z","shell.execute_reply":"2023-05-15T13:56:35.228333Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"The model has 10,325,546 trainable parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"attn_trainer.fit(1)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"p2gsN8xqFrY9","outputId":"afed9c90-50a3-4c40-b398-d27286039aea","execution":{"iopub.status.busy":"2023-05-15T13:56:35.230679Z","iopub.execute_input":"2023-05-15T13:56:35.232051Z","iopub.status.idle":"2023-05-15T14:33:19.052311Z","shell.execute_reply.started":"2023-05-15T13:56:35.232013Z","shell.execute_reply":"2023-05-15T14:33:19.051360Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"  0%|          | 0/1 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[100/1506][loss: 7.38][pp:1600.71]\n[200/1506][loss: 7.05][pp:1150.26]\n[300/1506][loss: 7.02][pp:1121.59]\n[400/1506][loss: 7.00][pp:1095.86]\n[500/1506][loss: 6.98][pp:1075.33]\n[600/1506][loss: 6.98][pp:1071.96]\n[700/1506][loss: 6.94][pp:1030.79]\n[800/1506][loss: 6.90][pp:995.39]\n[900/1506][loss: 6.98][pp:1079.98]\n[1000/1506][loss: 6.83][pp:929.24]\n[1100/1506][loss: 6.81][pp:907.23]\n[1200/1506][loss: 6.78][pp:883.11]\n[1300/1506][loss: 6.78][pp:882.42]\n[1400/1506][loss: 6.71][pp:822.71]\n[1500/1506][loss: 6.63][pp:760.39]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [36:43<00:00, 2203.81s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch with best validation loss: 01\nEpoch: 01 | Time: 36m 43s\n\tTrain Loss: 0.031 | Train PPL:   1.031\n\t Val. Loss: 6.859 |  Val. PPL: 952.078\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss = attn_trainer.evaluate(test_dataloader)\nprint(f'\\t Test. Loss: {test_loss:.3f} |  Test. PPL: {math.exp(test_loss):7.3f}')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TuTm_eUz6V5H","outputId":"3456d2c1-2bce-4f7c-f29e-6754b217bf96","execution":{"iopub.status.busy":"2023-05-15T14:33:19.053626Z","iopub.execute_input":"2023-05-15T14:33:19.054338Z","iopub.status.idle":"2023-05-15T14:36:20.863984Z","shell.execute_reply.started":"2023-05-15T14:33:19.054303Z","shell.execute_reply":"2023-05-15T14:36:20.862855Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\t Test. Loss: 6.854 |  Test. PPL: 948.065\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict(trainer, iterator):\n    trainer.model.eval()\n    decoded_batch_list = []\n    with torch.no_grad():\n\n        for i, batch in enumerate(tqdm(iterator)):\n\n            src = batch[0].transpose(0, 1)\n            trg = batch[1].transpose(0, 1)\n\n            decoded_batch = trainer.model.decode(src, trg, method='beam-search')\n            decoded_batch_list.append(decoded_batch)\n\n    return decoded_batch_list\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T14:36:20.865349Z","iopub.execute_input":"2023-05-15T14:36:20.865721Z","iopub.status.idle":"2023-05-15T14:36:20.872490Z","shell.execute_reply.started":"2023-05-15T14:36:20.865684Z","shell.execute_reply":"2023-05-15T14:36:20.871502Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"test_tensor = predict(attn_trainer, test_dataloader)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIXVuKhq6fTE","outputId":"436d3a5a-2d0c-46cd-9e8c-6db9cf526017","execution":{"iopub.status.busy":"2023-05-15T14:36:20.874106Z","iopub.execute_input":"2023-05-15T14:36:20.874717Z","iopub.status.idle":"2023-05-15T16:27:55.136077Z","shell.execute_reply.started":"2023-05-15T14:36:20.874683Z","shell.execute_reply":"2023-05-15T16:27:55.134967Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"100%|██████████| 323/323 [1:51:34<00:00, 20.73s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"for sentence_index in test_tensor[3]:\n    decode_text_arr = [y_tokenizer.index_word[int(i.to('cpu'))] for i in sentence_index[0]]\n    decode_stentence = \" \".join(decode_text_arr[1:-1])\n    print(\"pred target : {}\".format(decode_stentence))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T16:28:35.323488Z","iopub.execute_input":"2023-05-15T16:28:35.323966Z","iopub.status.idle":"2023-05-15T16:28:35.369066Z","shell.execute_reply.started":"2023-05-15T16:28:35.323926Z","shell.execute_reply":"2023-05-15T16:28:35.368175Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"pred target : một số bay của cho biết cho biết đã được cho biết cho biết đã được cho\npred target : tổng thống mỹ trung quốc cho rằng trung quốc\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm công an tp hcm đã\npred target : tổng thống mỹ triều tiên tổng thống mỹ triều tiên tổng thống mỹ triều tiên triều tiên triều tiên triều tiên\npred target : tổng thống mỹ triều tiên trung quốc cho\npred target : sau khi công an tp hcm tp hcm tp hcm tp hcm tp hcm đã tp hcm đã tp hcm đã\npred target : sau khi công an tp hcm tp hcm tp hcm tp hcm tp hcm đã tp hcm đã tp hcm đã\npred target : sau khi thông tin giao thông tin giao thông tin giao thông tin giao thông tin giao thông tin giao thông tin giao thông tin giao thông tin giao thông tin\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã tp hcm công an tp hcm\npred target : tổng thống mỹ triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên\npred target : sau khi thông tin thông tin cho biết thông tin thông tin\npred target : sau khi công an tp hcm cho biết tp hcm đã tp hcm đã tp hcm cho biết\npred target : sau khi thông tin thông tin cho biết cho biết\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã công an tp hcm\npred target : sau khi thông tin thông tin cho biết đã cho\npred target : tổng thống mỹ donald trump trung quốc cho biết tổng thống trung quốc\npred target : tổng thống mỹ donald trump trung quốc gia\npred target : một số bay của cho biết cho biết cho biết\npred target : tổng thống mỹ donald trump trung quốc sẽ\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã công an tp hcm\npred target : một quan chức năng thông tin quốc cho biết\npred target : tổng thống mỹ trung quốc cho trung quốc\npred target : tổng thống mỹ triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên\npred target : sau khi thông tin cho biết\npred target : sau khi thông tin thông tin cho biết cho biết thông\npred target : tổng thống mỹ triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên\npred target : tổng thống mỹ triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên\npred target : một số bay của cho biết cho biết cho biết\npred target : một quan chức năng thông tin cho biết đã\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã tp hcm công an tp hcm\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã tp hcm công an tp hcm\npred target : sau khi thông tin công an tp hcm đã tp hcm đã tp hcm đã cho biết\npred target : tổng thống mỹ trung quốc cho rằng triều tiên cho\npred target : sau khi thông tin thông tin cho biết thông tin thông\npred target : tổng thống mỹ triều tiên tổng thống mỹ donald trump triều tiên triều tiên triều tiên\npred target : tổng thống mỹ donald trump cho rằng trung quốc cho rằng\npred target : tổng thống mỹ triều tiên tổng thống mỹ triều tiên\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã tp hcm công an tp hcm\npred target : sau khi công an tp hcm công an tp hcm tp hcm tp hcm tp hcm tp hcm đã tp hcm đã công an\npred target : sau khi công an tp hcm tp hcm tp hcm tp hcm tp hcm đã tp hcm công an tp hcm\npred target : sau khi công an tp hcm tp hcm tp hcm tp hcm tp hcm tp hcm tp hcm đã tp hcm\npred target : tổng thống mỹ triều tiên triều tiên tổng thống mỹ quốc\npred target : một người dân công an tp hcm đã công an tp hcm cho biết công an tp hcm cho biết công an tp hcm\npred target : công an tỉnh công an tp hcm cho biết công an tp hcm cho biết công an tp hcm công an tp hcm\npred target : tổng thống mỹ donald trump triều tiên tổng thống triều tiên triều tiên\npred target : tổng thống mỹ donald trump trung quốc cho biết trung quốc sẽ được\npred target : sau khi thông tin thông tin cho biết cho biết\npred target : sau khi công an tp hcm đã tp hcm đã tp hcm cho biết đã\npred target : tổng thống mỹ donald trump cho biết trung quốc sẽ\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã công an tp hcm\npred target : một người dân của cho biết đã được cho là một số bay đã được cho là những người dân\npred target : tổng thống mỹ triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên\npred target : công an tỉnh công an tp hcm cho biết công an tp hcm cho biết công an tp hcm công an tp hcm\npred target : sau khi thông tin\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã công an tp hcm\npred target : sau khi thông tin công\npred target : tổng thống mỹ trung quốc cho biết\npred target : sau khi thông tin giao thông tin giao thông tin giao thông tin giao thông tin giao thông tin giao thông tin thông\npred target : tổng thống mỹ trung quốc cho trung quốc cho biết\npred target : sau khi thông tin cho biết cho\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã tp hcm công an tp hcm\npred target : sau khi công an tp hcm cho biết công an tp hcm đã tp hcm đã tp hcm đã tp hcm công an tp hcm\npred target : tổng thống mỹ donald trump trung quốc cho rằng trung\npred target : tổng thống mỹ triều tiên trung quốc triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên triều tiên\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Text: \", x_test[4])\nprint(\"Predict summary: \", get_sentence(test_out_attn[4], y_tokenizer))\nprint(\"True summary: \", y_test[4])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugS6v_ma6nDW","outputId":"cd8ad47d-401a-4d0c-ac10-876d6de3a4f2","execution":{"iopub.status.busy":"2023-05-15T16:27:55.178695Z","iopub.execute_input":"2023-05-15T16:27:55.179023Z","iopub.status.idle":"2023-05-15T16:27:55.417967Z","shell.execute_reply.started":"2023-05-15T16:27:55.178999Z","shell.execute_reply":"2023-05-15T16:27:55.416431Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Text:  <sos> sau khi đẻ rơi trên đường , mẹ con sản_phụ nguyễn_thị_hằng được 2 thanh_niên cùng quê chở đến bệnh_viện , hiện sức_khoẻ bình_phục . ảnh : giang_chinh 2h ngày 28/4 , chị nguyễn_thị_hằng ( 26 tuổi , trú xã tân_dương , thuỷ_nguyên , tp hải_phòng ) kêu đau đẻ , được chồng chở bằng xe_máy đến bệnh_viện đa_khoa huyện thuỷ_nguyên . ra khỏi nhà khoảng 2 km , chị hằng trở_dạ và sinh luôn trên đường , đoạn thuộc khu_phố mới , xã thuỷ_sơn . trong đêm_tối , người chồng để vợ nằm xuống đất và đỡ_đẻ . bé gái 3,3 kg chào_đời khoẻ_mạnh . không gọi được taxi cũng như xe cấp_cứu , người chồng ôm con đứng vẫy ôtô qua_lại , nhưng không ai dừng xe . bà văn_thị_thoa , mẹ chị hằng kể , khi đi xe_máy đến_nơi , bà thấy con đã sinh , nằm sõng_soài dưới đất , còn chồng ủ ấm cho cháu bé . hai mẹ_con vẫy xe nhưng không được . \" tôi đã nghĩ nếu không có xe , trời mưa nặng hạt hơn sẽ phải gõ_cửa , làm_phiền nhà dân thì chiếc ôtô màu đen chạy tới . 2 thanh_niên trên xe bước xuống , hỏi chuyện , rồi đưa 2 mẹ con nó đi viện \" , bà thoa kể . anh nam và bạn đưa mẹ con sản_phụ hằng đến bệnh_viện đa_khoa huyện thuỷ_nguyên cấp_cứu . hai người giúp mẹ_con chị hằng là anh nguyễn_thành_nam ( 31 tuổi ) và anh đào_bá_hiền ( 27 tuổi , đều ở huyện thuỷ_nguyên ) . sau khi đưa sản_phụ tới bệnh_viện , trưa cùng ngày anh nam đã quay lại thăm_hỏi và tặng quà . chia_sẻ trên facebook cá_nhân , anh nam cho biết , luôn quan_niệm phải giúp_đỡ người khác . trong cuộc_sống hàng ngày hay khi tham_gia giao_thông , anh đều sẵn_sàng giúp_đỡ người khác bằng mọi cách có_thể . \" mọi việc mình làm đều xuất_phát từ tâm và muốn làm nhiều điều tốt để tích đức cho con_cháu \" , anh nói . các bác_sĩ bệnh_viện thuỷ_nguyên cho biết , sức_khoẻ mẹ_con chị hằng đều tốt , trong 4-5 ngày tới sẽ được xuất_viện . giang_chinh   sau khi đẻ rơi trên đường , mẹ con sản_phụ nguyễn_thị_hằng được 2 thanh_niên cùng quê chở đến bệnh_viện , hiện sức_khoẻ bình_phục .  <eos>\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText: \u001b[39m\u001b[38;5;124m\"\u001b[39m, x_test[\u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredict summary: \u001b[39m\u001b[38;5;124m\"\u001b[39m, get_sentence(\u001b[43mtest_out_attn\u001b[49m[\u001b[38;5;241m4\u001b[39m], y_tokenizer))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue summary: \u001b[39m\u001b[38;5;124m\"\u001b[39m, y_test[\u001b[38;5;241m4\u001b[39m])\n","\u001b[0;31mNameError\u001b[0m: name 'test_out_attn' is not defined"],"ename":"NameError","evalue":"name 'test_out_attn' is not defined","output_type":"error"}]}]}